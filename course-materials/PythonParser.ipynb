{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Building a Parser in Python\n",
    "As discussed in class, each of our implementation languages makes one of either the lexer, parser or interpreter difficult. For Python, the parser is difficult as building a parser tree is one of a class of algorithms that is challenging to create iteratively while being easier when decomposed recursively (or functionally). As such, you should think of each subtree as its own problem. Also, each of these problems addresses a single grammar rule (e.g. `<Program> -> <Statement> <Program> | <Statement>`). \n",
    "\n",
    "The reference code for this Jupyter Notebook is from [PartialParser.py](https://github.com/dr-jam/csc521/blob/master/course-materials/PartialParser.py).\n",
    "\n",
    "##Basics\n",
    "###Token Stream\n",
    "The parser takes a token stream as a input. In the full version of your Quirk implementations, the parser will begin by reading the full set of tokens (including and EOF token at the very end of the stream) via standard input and store them in a global array named tokens.\n",
    "For testing purposes, you can declare a list of tokens to test with. An example would be:\n",
    "```python\n",
    "tokens = [\"VAR\", \"IDENT:X\", \"ASSIGN\", \"NUMBER:4\", \"EOF\"]\n",
    "```\n",
    "You can see more examples at the top of [PartialParser.py](https://github.com/dr-jam/csc521/blob/master/course-materials/PartialParser.py).\n",
    "\n",
    "####Token Index\n",
    "Each of the grammar functions has a single parameter called `token_index` which contains the position in the `token` list where the grammar should begin parsing from. This is not kept globally like `token` as grammar functions can fail. Keeping the relevant index locally in each function makes backtracking on grammar failure substantially easier.\n",
    "\n",
    "##Return Values of Grammar Functions\n",
    "\n",
    "The return values of each of these grammar functions is a list of three values:\n",
    "1. A boolean value that is Ture if a subtree that corresponds to the grammar found and False if not.\n",
    "2. The position into the list of tokens where the grammar function left off.\n",
    "3. The parse tree generated by the grammar function.\n",
    "\n",
    "Here is an example of using multiple variable assignemnt to pull out each of thse values in the return value list into their own local variable names:\n",
    "```python\n",
    "(success, returned_index, returned_subtree) = Statement(token_index)\n",
    "```\n",
    "\n",
    "Here is an example the return values of a call to the `Expression` grammar function where it successfuly parsed `-x`:\n",
    "```Python\n",
    "[True,\n",
    " 2,\n",
    " ['Expression2', ['Term2', ['Factor4', ['Value0', ['Name1', 'SUB', 'IDENT:X']]]]]\n",
    "]\n",
    "```\n",
    "with:\n",
    "```python\n",
    "tokens = [\"SUB\", \"IDENT:X\", \"EOF\"]\n",
    "```\n",
    "\n",
    "Unsuccessful parses return `False`, the `token_index` passed in to the grammar function that failed, and an empty subtree:\n",
    "```python\n",
    "return [False, token_index, []]\n",
    "```\n",
    "\n",
    "\n",
    "Consider the following part of the parser that was given to you in PartialParser.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Number(token_index):\n",
    "    '''<Number> ->\n",
    "        NUMBER\n",
    "        | SUB NUMBER\n",
    "        | ADD NUMBER\n",
    "    '''\n",
    "    if is_number(tokens[token_index]):\n",
    "        subtree = [\"Number0\", tokens[token_index]]\n",
    "        return [True, token_index + 1, subtree]\n",
    "    \n",
    "    if \"SUB\" == tokens[token_index]:\n",
    "        if is_number(tokens[token_index + 1]):\n",
    "            subtree = [\"Number1\", tokens[token_index], tokens[token_index + 1]]\n",
    "            return [True, token_index + 2, subtree]\n",
    "        \n",
    "    if \"ADD\" == tokens[token_index]:\n",
    "        if is_number(tokens[token_index + 1]):\n",
    "            subtree = [\"Number2\", tokens[token_index], tokens[token_index + 1]]\n",
    "            return [True, token_index + 2, subtree]\n",
    "        \n",
    "    return [False, token_index, []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the base cases that stops the recursive construction of the parse tree. You can tell that it is a base case because by looking at the replacement rules for <Number> and seeing that thay are all terminals (i.e. tokens). This function (along with it's counterpart the `Name` grammar function) creates leaves in the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
