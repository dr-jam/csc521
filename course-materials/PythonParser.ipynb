{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inspecting the Python Parser for Quirk\n",
    "As discussed in class, each of our implementation languages makes one of either the lexer, parser or interpreter difficult. For Python, the parser is difficult as building a parser tree is one of a class of algorithms that is challenging to create iteratively while being easier when decomposed recursively (or functionally). As such, you should think of each subtree as its own problem. Also, each of these problems addresses a single grammar rule (e.g. `<Program> -> <Statement> <Program> | <Statement>`). \n",
    "\n",
    "The reference code for this Jupyter Notebook is from [PartialParser.py](https://github.com/dr-jam/csc521/blob/master/course-materials/PartialParser.py).\n",
    "\n",
    "## Basics\n",
    "### Token Stream\n",
    "The parser takes a token stream as a input. In the full version of your Quirk implementations, the parser will begin by reading the full set of tokens (including and EOF token at the very end of the stream) via standard input and store them in a global array named tokens.\n",
    "For testing purposes, you can declare a list of tokens to test with. An example would be:\n",
    "```python\n",
    "tokens = [\"VAR\", \"IDENT:X\", \"ASSIGN\", \"NUMBER:4\", \"EOF\"]\n",
    "```\n",
    "You can see more examples at the top of [PartialParser.py](https://github.com/dr-jam/csc521/blob/master/course-materials/PartialParser.py).\n",
    "\n",
    "### Token Index\n",
    "Each of the grammar functions has a single parameter called `token_index` which contains the position in the `token` list where the grammar should begin parsing from. This is not kept globally like `token` as grammar functions can fail. Keeping the relevant index locally in each function makes backtracking on grammar failure substantially easier.\n",
    "\n",
    "### Return Values of Grammar Functions\n",
    "\n",
    "The return values of each of these grammar functions is a list of three values:\n",
    "1. A boolean value that is Ture if a subtree that corresponds to the grammar found and False if not.\n",
    "2. The position into the list of tokens where the grammar function left off.\n",
    "3. The parse tree generated by the grammar function.\n",
    "\n",
    "Here is an example of using multiple variable assignemnt to pull out each of thse values in the return value list into their own local variable names:\n",
    "```python\n",
    "(success, returned_index, returned_subtree) = Statement(token_index)\n",
    "```\n",
    "\n",
    "Here is an example the return values of a call to the `Expression` grammar function where it successfuly parsed `-x`:\n",
    "```Python\n",
    "[True,\n",
    " 2,\n",
    " ['Expression2', ['Term2', ['Factor4', ['Value0', ['Name1', 'SUB', 'IDENT:X']]]]]\n",
    "]\n",
    "```\n",
    "with:\n",
    "```python\n",
    "tokens = [\"SUB\", \"IDENT:x\", \"EOF\"]\n",
    "```\n",
    "\n",
    "Unsuccessful parses return `False`, the `token_index` passed in to the grammar function that failed (after all, failure shouldn't consume tokens as we want to use them again when after backtracking), and an empty subtree:\n",
    "```python\n",
    "return [False, token_index, []]\n",
    "```\n",
    "\n",
    "### Numbers After Nonterminals\n",
    "Note the numbers after the names of the nonterminals in the parse tree:\n",
    "```Python\n",
    "['Expression2', \n",
    "    ['Term2', \n",
    "        ['Factor4', \n",
    "            ['Value0', \n",
    "                ['Name1', 'SUB', 'IDENT:X']\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "```\n",
    "<a id=\"factors\"></a>Those numbers correspond to the replacement rule that the parser used to generated that part of the parse tree. These numbers are useful to the interpreter and are quite handy when debugging your parser. Take the the `<Factor>` portion of the grammar as an example:\n",
    "```\n",
    "<Factor> -> <SubExpression> EXP <Factor> | <SubExpression> | <FunctionCall> \n",
    "    | <Value> EXP <Factor> | <Value>\n",
    "```\n",
    "It contains fives ways to replace replace the nonterminal `<Factor>` (each of which is followed by its name in the parse tree) :\n",
    "0. `<SubExpression> EXP <Factor>` (Factor0)\n",
    "1. `<SubExpression>` (Factor1)\n",
    "2. `<FunctionCall>` (Factor2)\n",
    "3. `<Value> EXP <Factor>` (Factor3)\n",
    "4. `<Value>` (Factor4)\n",
    "\n",
    "There should be a replacement rule number after every nonterminal in your parse tree include those like `<Print>` that only have a single replacement rule.\n",
    "\n",
    "### Handling Token:Lexeme Pairs\n",
    "Utility functions that determine if a token is a NAME or NUMBER are provided for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_ident(tok):\n",
    "    '''Determines if the token is of type IDENT.\n",
    "    tok - a token\n",
    "    returns True if IDENT is in the token or False if not.\n",
    "    '''\n",
    "    return -1 < tok.find(\"IDENT\")\n",
    "\n",
    "def is_number(tok):\n",
    "    '''Determines if the token is of type NUMBER.\n",
    "    tok - a token\n",
    "    returns True if NUMBER is in the token or False if not.\n",
    "    '''\n",
    "    return -1 < tok.find(\"NUMBER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Grammar Function: Number\n",
    "Consider the following part of the parser that was given to you in PartialParser.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Number(token_index):\n",
    "    '''<Number> ->\n",
    "        NUMBER\n",
    "        | SUB NUMBER\n",
    "        | ADD NUMBER\n",
    "    '''\n",
    "    if is_number(tokens[token_index]):\n",
    "        subtree = [\"Number0\", tokens[token_index]]\n",
    "        return [True, token_index + 1, subtree]\n",
    "    \n",
    "    if \"SUB\" == tokens[token_index]:\n",
    "        if is_number(tokens[token_index + 1]):\n",
    "            subtree = [\"Number1\", tokens[token_index], tokens[token_index + 1]]\n",
    "            return [True, token_index + 2, subtree]\n",
    "        \n",
    "    if \"ADD\" == tokens[token_index]:\n",
    "        if is_number(tokens[token_index + 1]):\n",
    "            subtree = [\"Number2\", tokens[token_index], tokens[token_index + 1]]\n",
    "            return [True, token_index + 2, subtree]\n",
    "        \n",
    "    return [False, token_index, []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the base cases that stops the recursive construction of the parse tree. You can tell that it is a base case because by looking at the replacement rules for <Number> and seeing that thay are all terminals (i.e. tokens). This function (along with it's counterpart the `Name` grammar function) creates leaves in the parse tree.\n",
    "\n",
    "It contains four sections of code. The first three start with `if` statements and detect the token streams for the `Number0`, `Number1`, and `Number2` replacement rules. When they are successful, they build appropriate parse tree leaves for their cases. Note that the second and 3rd sections provide support for negative and positive numbers.\n",
    "\n",
    "Let's run the grammar function on a stream of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, 2, ['Number1', 'SUB', 'NUMBER:1.2']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"SUB\", \"NUMBER:1.2\", \"EOF\"]\n",
    "Number(0) #Starts parsing <Number> at the first token in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the return values of `Number(0)` in order, we can see that the token stream was successfully parsed:\n",
    "1. `True` - The grammar function returned success.\n",
    "2. `2` - The grammar function left the token index at position 2 (at `\"EOF\"`).\n",
    "3. `['Number1', 'SUB', 'NUMBER:1.2']` - The subtree returned was a parse tree leaf consisting of the 2nd rule to replace `<Number>` that consists of two tokens: `SUB` and `NUMBER:1.2`.\n",
    "Great! This is exactly what we would expect from our parser. \n",
    "\n",
    "The other grammar function that is a base case is `Name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Name(token_index):\n",
    "    '''<Name> ->\n",
    "        IDENT\n",
    "        | SUB IDENT\n",
    "        | ADD IDENT\n",
    "    '''\n",
    "    if is_ident(tokens[token_index]):\n",
    "        subtree = [\"Name0\", tokens[token_index]]\n",
    "        return [True, token_index + 1, subtree]\n",
    "    \n",
    "    if \"SUB\" == tokens[token_index]:\n",
    "        if is_ident(tokens[token_index + 1]):\n",
    "            subtree = [\"Name1\", tokens[token_index], tokens[token_index + 1]]\n",
    "            return [True, token_index + 2, subtree]\n",
    "        \n",
    "    if \"ADD\" == tokens[token_index]:\n",
    "        if is_ident(tokens[token_index + 1]):\n",
    "            subtree = [\"Name2\", tokens[token_index], tokens[token_index + 1]]\n",
    "            return [True, token_index + 2, subtree]\n",
    "        \n",
    "    return [False, token_index, []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build up from here with a grammar function that is not a base case.\n",
    "## Another Layer: Value\n",
    "\n",
    "`<Value>` is where we choose between using `<Name>` or `<Number>` in arithematic expressions. Luckily for us, we already have the `Name` and `Number` grammar functions to do the heavy lifting; all that we need to do is to call those functions and see which, if any, succeeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Value(token_index):\n",
    "    '''\n",
    "    <Value> ->\n",
    "        <Name>\n",
    "        | <Number>\n",
    "    '''\n",
    "    (success, returned_index, returned_subtree) = Name(token_index)\n",
    "    if success:\n",
    "        return [True, returned_index, [\"Value0\", returned_subtree]]\n",
    "    \n",
    "    #<number>\n",
    "    (success, returned_index, returned_subtree) = Number(token_index)\n",
    "    if success:\n",
    "        return [True, returned_index, [\"Value1\", returned_subtree]]\n",
    "    \n",
    "    return [False, token_index, []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `Value` on the previous `token` list results in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, 2, ['Value1', ['Number1', 'SUB', 'NUMBER:1.2']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Value(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Factor\n",
    "`<Factor>` is one of Quirk's more interesting grammar rules as it contains 5 replacement rules (see [the description of Factor](#factors) above). We will focus on the last two of those replacement rules in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Factor(token_index):\n",
    "    '''\n",
    "    <Factor> ->\n",
    "        <SubExpression>\n",
    "        | <SubExpression> EXP <Factor>\n",
    "        | <FunctionCall>\n",
    "        | <Value> EXP <Factor>\n",
    "        | <Value>\n",
    "    '''\n",
    "    #Factor0, Factor1, and Factor2 are ommitted for this example are in PartialParser.py\n",
    "    \n",
    "    #<Value> EXP <Factor>\n",
    "    (success, returned_index, returned_subtree) = Value(token_index)\n",
    "    if success:\n",
    "        subtree = [\"Factor3\", returned_subtree]\n",
    "        if \"EXP\" == tokens[returned_index]:\n",
    "            subtree.append(tokens[returned_index])\n",
    "            (success, returned_index, returned_subtree) = Factor(returned_index + 1)\n",
    "            if success:\n",
    "                subtree.append(returned_subtree)\n",
    "                return [True, returned_index, subtree]\n",
    "\n",
    "    #<Value>\n",
    "    (success, returned_index, returned_subtree) = Value(token_index)\n",
    "    if success:\n",
    "        return [True, returned_index, [\"Factor4\", returned_subtree]]\n",
    "    \n",
    "    return [False, token_index, []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implmentation of `Factor` features three sections: `\"Factor3\"`, `\"Factor4\"`, and the failure case. The second section, `\"Factor4\"` simply calls `Value` and examples the results. The first section, `\"Factor3\"` is more interesting as it consists of `<Value> EXP <Factor>`. Because the `\"Factor3\"` replacement rule has three parts, it's implementation requires three conditionals: one to check for each part of the replacement rule. If any fail, `\"Factor3\"` does not parse. If all succeed, then `\"Factor3\"` succeeds. Note the mixed use of nonterminals and terminals in the replacement rule.\n",
    "\n",
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " 6,\n",
       " ['Factor3',\n",
       "  ['Value0', ['Name1', 'SUB', 'IDENT:x']],\n",
       "  'EXP',\n",
       "  ['Factor3',\n",
       "   ['Value1', ['Number0', 'NUMBER:4']],\n",
       "   'EXP',\n",
       "   ['Factor4', ['Value0', ['Name0', 'IDENT:x']]]]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"SUB\", \"IDENT:x\", \"EXP\", \"NUMBER:4\", \"EXP\", \"IDENT:x\", \"EOF\"]\n",
    "Factor(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! You should carefully inspect the output and see if it matches your idea of what the parse tree should look like for fragment of Quirk code starting with `Factor`:\n",
    "```\n",
    "-x ^ 4 ^ x\n",
    "```\n",
    "Lets intentionally try to break our parser by putting two `\"EXP\"` tokens in a row at indexes 2 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, 2, ['Factor4', ['Value0', ['Name1', 'SUB', 'IDENT:X']]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"SUB\", \"IDENT:X\", \"EXP\", \"EXP\", \"NUMBER:4\", \"EXP\", \"IDENT:X\", \"EOF\"]\n",
    "Factor(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be saying \"Hey, wait! Wasn't that suppposed to fail? The first value is `True`, not `False`!\" You would be correct as there are still unconsumed tokens that are not `\"EOF\"` (the return values left the token stream at index 2). In this case, we are only using a small amout of the grammar. Your parser should check for unused tokens that are not `\"EOF\"` after you parse the entire program with the `Program` grammar function over the entire token stream. You should then check to see if the 2nd value in the list of return values indexes to `\"EOF\"` in the `tokens` list. If it does, you successfully (please check for bugs!) parsed the token stream and generated a parse tree for the interpreter to use."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
